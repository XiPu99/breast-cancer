---
title: "Final project report"
author: "Tong Wu, Xi Pu"
date: "4/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
library(corrplot)
library(rstanarm)
library(patchwork)
library(bayesplot)
library(caret)
library(loo)
```

## Introduction

Breast cancer is one of the most prominent forms of cancer in the US and one of the deadliest besides lung cancer. In fact, about 1 in 8 US women will develop breast cancer in the course of their lifetime and the around 40,000 women are expected to die from breast cancer in 2020. Diagnosis of breast cancer involves an initial screening with mammogram for a tumor, followed by a biopsy of the cancerous tissue. Pathologists typically analyze the tissue, noting its size, shape, texture, and color, before determining whether the tumor is benign (harmless), or malignant (has metastasized). However, demands for automating this classification for basic tumors is rising as physicians are inundated with tests after tests in an aging US population. To improve efficiency of breast cancer diagnosis, it is good to develop a model that could analyze measurements regarding the tumor taken from images of these slides and accurately predict whether the tumor is benign or malignant. 

To address this need, we will use the data from the Breast Cancer Wisconsin (Diagnostic) Data Set to develop a Bayesian logistic regression model that can accurately predict whether a tumor is benign or malignant, given the characteristic outputs provided by the image measurements. We will first generate a posterior logistic regression model including all 31 covariates present in the dataset, setting our prior initial estimates for the coefficients as the sample mean for each covariate. For the model generation, we plan on using MCMC sampling to determine the posterior coefficients. Since the data contains many highly correlated covariates, we will calculate the VIF for all the predictors, determine if there is a significant difference in M/B diagnostics for each predictor, and use both information to choose the most suitable predictors and remove the high VIF, non-significant predictors. Afterwards, we will update our model with only the significant predictors and perform the Bayesian analysis again to obtain the new posterior coefficients with confidence intervals. Next, we will evaluate our model by reducing autocorrelation (etc.). Finally, we will test this model through k-fold cross validation and observe our accuracy through ROC curves. Our goal is to develop an accurate logistic regression model that can accurately predict whether a tumor is malignant or benign given measurements in the Wisconsin dataset. This would help improve the efficiency of basic M/B diagnosis for breast cancer by automating the classification process. 

## Data

#### Data source

The dataset used for this project is the Wisconsin Diagnostic Breast Cancer Dataset. It can be accessed from this link https://www.kaggle.com/uciml/breast-cancer-wisconsin-data and can also be found on [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). All the data in the dataset is already in clean and workable format and there are no missing values present in the dataset.

This dataset has 569 observations and 32 variables. Each observation contains information about characteristics of the cell nuclei present in a digitized image of a fine needle aspirate (FNA) of a breast mass.
 
#### Data description

Variable Information:
1. ID number
2. Diagnosis: a binary response variable that either takes value M or B (M = malignant, B = benign)

__3-32)__

Ten numeric values are computed for each cell nucleus:
  1. radius (mean of distances from center to points on the perimeter)
  2. texture (standard deviation of gray-scale values)
  3. perimeter
  4. area
  5. smoothness (local variation in radius lengths)
  6. compactness (perimeter^2 / area - 1.0)
  7. concavity (severity of concave portions of the contour)
  8. concave points (number of concave portions of the contour)
  9. symmetry
  10. fractal dimension ("coastline approximation" - 1)
The mean, standard error and "worst" or largest (mean of the three
largest values) of these features were computed for each image,
resulting in 30 variables. For instance, field 3 is Mean Radius, field
13 is Radius SE, field 23 is Worst Radius.

#### Exploratory data analysis

Itâ€™s important to point out that since 20 of the 30 predictors were computed from data, high multicollinearity exists in this dataset.

```{r fig.height=7}
data <- read.csv("data.csv")
corrplot(cor(data[,-1:-2]), method = "color", tl.col="black", tl.srt=45)
```

As we can see from the plot above, some predictors are highly correlated. One way we can deal with this is transforming the predictors using principal component analysis(PCA). We can then perform logistic regression on PCA transformed variables. However, the problem is that the model is not interpretable if we use PCA transformed variables. One of the biggest advantage of logistic regression is interpretability. By using PCA variables, we loose that advantage. So, instead, we use Variance inflation factor (VIF) as the criteria to remove multicollinearity.

## Model

We are performing a Bayesian analysis of the coefficients for the covariates in a logistic regression model that can predict whether a tumor is malignant or benigh. We set our prior estimate for the coefficients as a vector of t-distribution's centered around 0. The prior estimates are centered around zero because we do not have enough information to knnow whether each covariate is a significant predictor for the diagnosis. We chose a t-distribution because we don't have enough prior information to say that the coefficient is close to 0. Our sampling probability model will be IID Bernouli distributions because the response variable (diagnosis) is binary. Then we obtain the posterior distribution for the coefficients via MCMC sampling. 
Below is the posterior distribution that stan_glm will draw from when using MCMC.

```{r cache=TRUE}
SEED=20200425
t_prior <- student_t(df = 1, location = 0, scale = 5)
post1 <- stan_glm(diagnosis ~ ., data = data[,-1],
                 family = binomial(link = "logit"), 
                 prior = t_prior, prior_intercept = t_prior, QR=TRUE,
                 seed = SEED, iter = 2000, chain = 1, refresh = 0)
```

Below is the posterior coefficients generated from our Bayesian logistic regression model containing all the predictors. 

```{r}
car::vif(post1)
```

Remove all predictors that have relatively high VIF values:

```{r cache=TRUE}
post2 <- stan_glm(diagnosis ~ symmetry_mean + texture_se +
                    smoothness_se + symmetry_se + smoothness_mean, data = data[,-1],
                 family = binomial(link = "logit"), 
                 prior = t_prior, prior_intercept = t_prior, QR=TRUE,
                 seed = SEED, iter = 2000, chain = 1, refresh = 0)
```

```{r}
post3 <- stan_glm(diagnosis ~ symmetry_mean + texture_mean +
                    area_mean + concavity_mean, data = data[,-1],
                 family = binomial(link = "logit"), 
                 prior = t_prior, prior_intercept = t_prior, QR=TRUE,
                 seed = SEED, iter = 2000, chain = 1, refresh = 0)
```

Model coefficients and CI:
```{r}
round(coef(post3), 2)
round(posterior_interval(post3, prob = 0.9), 2)
car::vif(post3)
```

## Model diagnostics

```{r}
#color_scheme_set("red")
#mcmc_trace(post2, pars = c("texture_se", "symmetry_mean", "smoothness_se", "smoothness_mean"))
```

```{r}
#mcmc_acf(post2, pars = c("texture_se", "symmetry_mean", "smoothness_se", "smoothness_mean"), lags = 10)
```

```{r}
color_scheme_set("red")
mcmc_trace(post3, pars = c("texture_mean", "symmetry_mean", "area_mean", "concavity_mean"))
```

```{r}
mcmc_acf(post3, pars = c("texture_mean", "symmetry_mean", "area_mean", "concavity_mean"), lags = 10)
```

The traceplots for the coefficient of the four covariates indicates that there is immediate convergence and good mixing. This is backed up by the autocorrelation plots which show the autocorrelations greatly reduce between consecutive samples after only a few iterations. Thus, our model appears to have good performance with little to no burn-in before convergence as well as good mixing. 

#### Results

## Posterior predictive diagnostics

For posterior predictive checks, we used the 1000 posterior samples generated during the MCMC sampling to get our final prediction. Since each posterior sample contains predictions for all 569 observations, for each observation, we calculated the proportion of samples that are predicted to be malignant. If the proportion is above 0.5, then we conclude that this observation is a malignant case and benign otherwise. We can then generate a confusion matrix based on the final prediction to evaluate the performance of our model.

```{r}
pred <- posterior_predict(post3)
pr <- factor(as.integer(colMeans(pred) >= 0.5))
levels(pr) <- c("B", "M")
caret::confusionMatrix(pr, data$diagnosis)[2]
caret::confusionMatrix(pr, data$diagnosis)$overall["Accuracy"]
```

The accuracy of our predictions is about 92.8%. Even though our posterior predictive analysis shows that the model gives us very accurate predictions, there might be overfitting issues since we are testing on the training set, which is the dataset we used to fit our model earlier. So, to further test our posterior predictions and see if overfitting exists, we decided to use the `loo` package to perform a leave-one-out cross validation test.

```{r message=FALSE, warning=FALSE}
loo1 <- loo(post3, save_psis = TRUE)
ploo <- E_loo(pred, loo1$psis_object, type="mean", log_ratios = -log_lik(post3))$value
#round(mean(xor(ploo>0.5,as.integer(y==0))),2)
mean(xor(ploo>0.5,as.integer(data$diagnosis=="B")))
#mean( (ploo>0.5 & as.integer(data$diagnosis=="M")) | (ploo<0.5 & as.integer(data$diagnosis=="B")) )
```

The result shows an accuracy of 92.6%, which is very close to the accuracy we got earlier when we tested the predictions using the training set. This indicates that our model indeed is a good fit for accurately predicting malignant vs benigh tumors. 

## Model interpretation


```{r}
round(coef(post3), 2)
round(posterior_interval(post3, prob = 0.9), 2)
car::vif(post3)
```


From the model coefficient and CI outputs, we see that:
Intercept: At baseline when all other covariates are set to zero, the log odds of malignant over benigh tumor is -21.66 with 90% CI (-26.27, -17.78). This makes sense because we expect that a tumor with no area, texture, symmetry, and concavity would not appear to be a tumor at all and thus would be classified as benigh. 
Symmetry: Holding all else constant, for every unit increase in symmetry_mean, the log odds that the tumor is malignant over benigh is expected to increase by 31.52, which 90% CI (16.94, 47.23). This suggests that the symmetry of the tumor is associated with a big role in diagnosing malignant tumors or benigh tumors. 
Texture: Holding all else constant, for every unit increase in the mean texture (deviation from the gray scale), the log odds that the tumor is malignant over benigh is expected to increase by .28 with 90% CI (.21, .37). The low magnitude of the slope suggests that texture does not play as big of a role in favoring the odds of malignant over benigh diagnosis.
Area: Holding all else constant, for every unit increase in the area of the tumor, the log odds that the tumor is malignant over benigh is expected to increase by 0.01 with a 90% CI (.01, .02). The magnitude of this slope is significant but very close to 0, indicating that area of the tumor does not play a big role in favoring the odds of malignant over benigh diagnosis. 
Concavity: Holding all else constant, for every unit increase in the tumor's mean of severity of concave portions of the contour, the log odds that the tumor is malignant over benigh is expected to increase by 21.44, with 90% CI (15.33, 27.85). The large magnitude of this slope suggests that the severity of concave portions of the tumor plays a big role in favoring the odds of diagnosing malignant over benigh for a tumor. 



## Conclusion

